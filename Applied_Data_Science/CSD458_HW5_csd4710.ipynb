{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gtsagkatakis/Data-Science-and-Applications/blob/main/CSD458_HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqhxzc5tSO6d"
      },
      "source": [
        "# CS485: Data Science and Applications\n",
        "## Assignment 5 : Classify Fashion MNist images using CNNs\n",
        "### Vasileios Papageridis - csd4710\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBUI4-BVY7qe"
      },
      "source": [
        "\n",
        "\n",
        "### **PART A: Training Convolutional Neural Networks (CNNs)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "dv3Y0wYEzLtM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.v2 as v2\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.optim as optim\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acp_308rSHbj"
      },
      "source": [
        "\n",
        "#### 1. Download the Fashion Mnist Dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qymVpNyLZAap"
      },
      "source": [
        "#### 2. Define the Dataset, Dataloader, Transforms. Use v2.Compose() to include even more transforms, such as rotations, crops and others.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dFOjGnwxyn53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of classes: 10\n"
          ]
        }
      ],
      "source": [
        "# Training transformations with augmentation\n",
        "train_transform = v2.Compose([\n",
        "    v2.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),    # Random rotation, translation, and scale\n",
        "    v2.RandomCrop(28, padding=4),                                           # Random crop with padding\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize((0.5,), (0.5,)),\n",
        "])\n",
        "\n",
        "# Test transformations without augmentation\n",
        "test_transform = v2.Compose([\n",
        "    v2.ToImage(),\n",
        "    v2.ToDtype(torch.float32, scale=True),\n",
        "    v2.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=train_transform)\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n",
        "num_classes = len(classes)\n",
        "print('Number of classes:', num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vX6lT_wZCHx"
      },
      "source": [
        "#### 3. Make your own version of CNN and report the validatation set accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, padding=2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(64 * 3 * 3, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = CustomCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Mini-batch 40\n",
            "Avg losses 1.966175478696823 1.2550132517602033\n",
            "Epoch 1, Mini-batch 80\n",
            "Avg losses 1.4010122001171113 0.9918670551792071\n",
            "Epoch 1, Mini-batch 120\n",
            "Avg losses 1.165960742533207 0.8882363525925169\n",
            "Epoch 1, Mini-batch 160\n",
            "Avg losses 1.0235280334949493 0.852897998633658\n",
            "Epoch 1, Mini-batch 200\n",
            "Avg losses 0.9223049134016037 0.7549993253437577\n",
            "Epoch 1, Mini-batch 240\n",
            "Avg losses 0.8800206527113914 0.754809378059047\n",
            "Epoch 1, Mini-batch 280\n",
            "Avg losses 0.8522170141339303 0.7596914403757472\n",
            "Epoch 1, Mini-batch 320\n",
            "Avg losses 0.8507828488945961 0.7086971404066511\n",
            "Epoch 1, Mini-batch 360\n",
            "Avg losses 0.7998210445046425 0.7029060341749981\n",
            "Epoch 1, Mini-batch 400\n",
            "Avg losses 0.7617340311408043 0.677240739962098\n",
            "Epoch 1, Mini-batch 440\n",
            "Avg losses 0.7845756053924561 0.6791489978504789\n",
            "Epoch 1, Mini-batch 480\n",
            "Avg losses 0.7197679497301579 0.654558840640791\n",
            "Epoch 1, Mini-batch 520\n",
            "Avg losses 0.7394823916256428 0.6267067567937693\n",
            "Epoch 1, Mini-batch 560\n",
            "Avg losses 0.7299331486225128 0.6391792443527538\n",
            "Epoch 1, Mini-batch 600\n",
            "Avg losses 0.7302320301532745 0.6343680441759194\n",
            "Epoch 1, Mini-batch 640\n",
            "Avg losses 0.6758155643939971 0.6411572083546098\n",
            "Epoch 1, Mini-batch 680\n",
            "Avg losses 0.7127056956291199 0.610813797279528\n",
            "Epoch 1, Mini-batch 720\n",
            "Avg losses 0.6852484852075577 0.6890160788776009\n",
            "Epoch 1, Mini-batch 760\n",
            "Avg losses 0.6805490277707577 0.5757220715853819\n",
            "Epoch 1, Mini-batch 800\n",
            "Avg losses 0.6471504658460617 0.615865230370479\n",
            "Epoch 1, Mini-batch 840\n",
            "Avg losses 0.7254575811326504 0.5989035935538589\n",
            "Epoch 1, Mini-batch 880\n",
            "Avg losses 0.6882806845009327 0.5751772665294113\n",
            "Epoch 1, Mini-batch 920\n",
            "Avg losses 0.6524118840694427 0.5774665598277073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [01:58<07:54, 118.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Mini-batch 40\n",
            "Avg losses 0.6338512025773525 0.5645566053071599\n",
            "Epoch 2, Mini-batch 80\n",
            "Avg losses 0.6475940138101578 0.5438023203877127\n",
            "Epoch 2, Mini-batch 120\n",
            "Avg losses 0.6018777124583721 0.5595501365175672\n",
            "Epoch 2, Mini-batch 160\n",
            "Avg losses 0.6359315931797027 0.5640308541856753\n",
            "Epoch 2, Mini-batch 200\n",
            "Avg losses 0.6499474242329597 0.5428824954351802\n",
            "Epoch 2, Mini-batch 240\n",
            "Avg losses 0.6209296651184559 0.5767283234626625\n",
            "Epoch 2, Mini-batch 280\n",
            "Avg losses 0.6497160255908966 0.5408622259926644\n",
            "Epoch 2, Mini-batch 320\n",
            "Avg losses 0.6238526046276093 0.5202381189461727\n",
            "Epoch 2, Mini-batch 360\n",
            "Avg losses 0.6191851407289505 0.5428050634967294\n",
            "Epoch 2, Mini-batch 400\n",
            "Avg losses 0.6032769426703453 0.5726488027603004\n",
            "Epoch 2, Mini-batch 440\n",
            "Avg losses 0.6153452225029469 0.5122244451076362\n",
            "Epoch 2, Mini-batch 480\n",
            "Avg losses 0.6119692161679268 0.5331991802734933\n",
            "Epoch 2, Mini-batch 520\n",
            "Avg losses 0.5855738908052445 0.5027187958264806\n",
            "Epoch 2, Mini-batch 560\n",
            "Avg losses 0.5847527854144573 0.5156723539920369\n",
            "Epoch 2, Mini-batch 600\n",
            "Avg losses 0.5683623798191547 0.5013631253865114\n",
            "Epoch 2, Mini-batch 640\n",
            "Avg losses 0.5926361724734306 0.5520978970512463\n",
            "Epoch 2, Mini-batch 680\n",
            "Avg losses 0.5869615487754345 0.5085342706768377\n",
            "Epoch 2, Mini-batch 720\n",
            "Avg losses 0.5878747262060642 0.5074183012649511\n",
            "Epoch 2, Mini-batch 760\n",
            "Avg losses 0.5340782955288887 0.4766399220676179\n",
            "Epoch 2, Mini-batch 800\n",
            "Avg losses 0.5670363739132881 0.49289584938128284\n",
            "Epoch 2, Mini-batch 840\n",
            "Avg losses 0.6055268935859204 0.4783848706324389\n",
            "Epoch 2, Mini-batch 880\n",
            "Avg losses 0.5622477501630783 0.4785971556119858\n",
            "Epoch 2, Mini-batch 920\n",
            "Avg losses 0.5711946286261081 0.48192509306464226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 2/5 [03:56<05:54, 118.07s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Mini-batch 40\n",
            "Avg losses 0.5773085080087185 0.476852302338667\n",
            "Epoch 3, Mini-batch 80\n",
            "Avg losses 0.5746854409575463 0.4907468481428304\n",
            "Epoch 3, Mini-batch 120\n",
            "Avg losses 0.570124065130949 0.4551806351181808\n",
            "Epoch 3, Mini-batch 160\n",
            "Avg losses 0.5387945465743542 0.46376910084372114\n",
            "Epoch 3, Mini-batch 200\n",
            "Avg losses 0.5382417902350426 0.4559672384694883\n",
            "Epoch 3, Mini-batch 240\n",
            "Avg losses 0.5359532743692398 0.4650439236574112\n",
            "Epoch 3, Mini-batch 280\n",
            "Avg losses 0.5596148714423179 0.4771991941579588\n",
            "Epoch 3, Mini-batch 320\n",
            "Avg losses 0.5544676430523395 0.5051843152873835\n",
            "Epoch 3, Mini-batch 360\n",
            "Avg losses 0.5262401163578033 0.4705125280436437\n",
            "Epoch 3, Mini-batch 400\n",
            "Avg losses 0.5339215934276581 0.45273286199114127\n",
            "Epoch 3, Mini-batch 440\n",
            "Avg losses 0.5336927011609077 0.44632236811385795\n",
            "Epoch 3, Mini-batch 480\n",
            "Avg losses 0.5114264152944088 0.44337294208016365\n",
            "Epoch 3, Mini-batch 520\n",
            "Avg losses 0.5245152443647385 0.45169606225885406\n",
            "Epoch 3, Mini-batch 560\n",
            "Avg losses 0.5117592848837376 0.47058145455114403\n",
            "Epoch 3, Mini-batch 600\n",
            "Avg losses 0.4910638205707073 0.46122989646948065\n",
            "Epoch 3, Mini-batch 640\n",
            "Avg losses 0.5211208924651146 0.4328346179359278\n",
            "Epoch 3, Mini-batch 680\n",
            "Avg losses 0.5384597703814507 0.4457670343909294\n",
            "Epoch 3, Mini-batch 720\n",
            "Avg losses 0.48733927607536315 0.42815975674018736\n",
            "Epoch 3, Mini-batch 760\n",
            "Avg losses 0.5161441795527935 0.427739122490974\n",
            "Epoch 3, Mini-batch 800\n",
            "Avg losses 0.5238397747278214 0.442536483050152\n",
            "Epoch 3, Mini-batch 840\n",
            "Avg losses 0.5053043842315674 0.43885949491315585\n",
            "Epoch 3, Mini-batch 880\n",
            "Avg losses 0.5200372643768787 0.431654809291955\n",
            "Epoch 3, Mini-batch 920\n",
            "Avg losses 0.4922051288187504 0.41771816789724264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 3/5 [05:53<03:55, 117.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Mini-batch 40\n",
            "Avg losses 0.5122621387243271 0.4314578038871668\n",
            "Epoch 4, Mini-batch 80\n",
            "Avg losses 0.4644552044570446 0.4228256426419422\n",
            "Epoch 4, Mini-batch 120\n",
            "Avg losses 0.4620510213077068 0.42797230525760893\n",
            "Epoch 4, Mini-batch 160\n",
            "Avg losses 0.5202819235622883 0.43961932818601085\n",
            "Epoch 4, Mini-batch 200\n",
            "Avg losses 0.48429241478443147 0.3970956584070898\n",
            "Epoch 4, Mini-batch 240\n",
            "Avg losses 0.5177335686981678 0.4333469351385809\n",
            "Epoch 4, Mini-batch 280\n",
            "Avg losses 0.4796363294124603 0.40593104766812294\n",
            "Epoch 4, Mini-batch 320\n",
            "Avg losses 0.4644170604646206 0.40924837596856867\n",
            "Epoch 4, Mini-batch 360\n",
            "Avg losses 0.47575378641486166 0.44162555371120477\n",
            "Epoch 4, Mini-batch 400\n",
            "Avg losses 0.5116599455475808 0.419753437968576\n",
            "Epoch 4, Mini-batch 440\n",
            "Avg losses 0.46743713691830635 0.4477881545283992\n",
            "Epoch 4, Mini-batch 480\n",
            "Avg losses 0.5071287162601947 0.4028544462979979\n",
            "Epoch 4, Mini-batch 520\n",
            "Avg losses 0.4967963628470898 0.41589965666555295\n",
            "Epoch 4, Mini-batch 560\n",
            "Avg losses 0.4598319686949253 0.42661891858668843\n",
            "Epoch 4, Mini-batch 600\n",
            "Avg losses 0.48050629943609235 0.4050910446294554\n",
            "Epoch 4, Mini-batch 640\n",
            "Avg losses 0.47547376304864886 0.4077643231032001\n",
            "Epoch 4, Mini-batch 680\n",
            "Avg losses 0.4932887263596058 0.4026525179102163\n",
            "Epoch 4, Mini-batch 720\n",
            "Avg losses 0.49732311591506007 0.39365445086910467\n",
            "Epoch 4, Mini-batch 760\n",
            "Avg losses 0.4753511555492878 0.4063005974148489\n",
            "Epoch 4, Mini-batch 800\n",
            "Avg losses 0.44501983672380446 0.4572674113853722\n",
            "Epoch 4, Mini-batch 840\n",
            "Avg losses 0.4673725165426731 0.3959317111475453\n",
            "Epoch 4, Mini-batch 880\n",
            "Avg losses 0.47058893777430055 0.4247711981367913\n",
            "Epoch 4, Mini-batch 920\n",
            "Avg losses 0.4627029798924923 0.3945399313975292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 4/5 [07:51<01:57, 117.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Mini-batch 40\n",
            "Avg losses 0.47497455552220347 0.39712736655952063\n",
            "Epoch 5, Mini-batch 80\n",
            "Avg losses 0.45545564591884613 0.3898034045460877\n",
            "Epoch 5, Mini-batch 120\n",
            "Avg losses 0.4336617711931467 0.3658695637610308\n",
            "Epoch 5, Mini-batch 160\n",
            "Avg losses 0.448314742743969 0.3691005250261088\n",
            "Epoch 5, Mini-batch 200\n",
            "Avg losses 0.4540612705051899 0.3853884371602611\n",
            "Epoch 5, Mini-batch 240\n",
            "Avg losses 0.42904839143157003 0.3919660084566493\n",
            "Epoch 5, Mini-batch 280\n",
            "Avg losses 0.4437387816607952 0.3757835695887827\n",
            "Epoch 5, Mini-batch 320\n",
            "Avg losses 0.4385156542062759 0.37177239614687146\n",
            "Epoch 5, Mini-batch 360\n",
            "Avg losses 0.46124288216233256 0.4572536609355052\n",
            "Epoch 5, Mini-batch 400\n",
            "Avg losses 0.4459034759551287 0.3662436679480182\n",
            "Epoch 5, Mini-batch 440\n",
            "Avg losses 0.44539742097258567 0.39821930011366585\n",
            "Epoch 5, Mini-batch 480\n",
            "Avg losses 0.4739050529897213 0.396826721775304\n",
            "Epoch 5, Mini-batch 520\n",
            "Avg losses 0.4547282762825489 0.36381181922687844\n",
            "Epoch 5, Mini-batch 560\n",
            "Avg losses 0.4823546566069126 0.3788561129076466\n",
            "Epoch 5, Mini-batch 600\n",
            "Avg losses 0.4726635441184044 0.3693761821765049\n",
            "Epoch 5, Mini-batch 640\n",
            "Avg losses 0.4646378427743912 0.39418249657958937\n",
            "Epoch 5, Mini-batch 680\n",
            "Avg losses 0.45362528860569 0.3832476295673164\n",
            "Epoch 5, Mini-batch 720\n",
            "Avg losses 0.4434471525251865 0.3697198529721825\n",
            "Epoch 5, Mini-batch 760\n",
            "Avg losses 0.4476279765367508 0.38336023602895675\n",
            "Epoch 5, Mini-batch 800\n",
            "Avg losses 0.4519985821098089 0.36052944909804946\n",
            "Epoch 5, Mini-batch 840\n",
            "Avg losses 0.45567513108253477 0.3677447331938774\n",
            "Epoch 5, Mini-batch 880\n",
            "Avg losses 0.4309478264302015 0.35238348630962857\n",
            "Epoch 5, Mini-batch 920\n",
            "Avg losses 0.43448466844856737 0.3540024512512669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [09:48<00:00, 117.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 40 == 39:    # Every 1000 mini-batches...\n",
        "            print(f'Epoch {epoch + 1}, Mini-batch {i + 1}')\n",
        "            # Check against the validation set\n",
        "            running_vloss = 0.0\n",
        "\n",
        "            # In evaluation mode some model specific operations can be omitted\n",
        "            model.train(False) # Switching to evaluation mode\n",
        "            for j, vdata in enumerate(testloader, 0):\n",
        "                vinputs, vlabels = vdata\n",
        "                voutputs = model(vinputs)\n",
        "                vloss = criterion(voutputs, vlabels)\n",
        "                running_vloss += vloss.item()\n",
        "\n",
        "            model.train(True) # Switching back to training mode\n",
        "            avg_loss = running_loss / 40\n",
        "            avg_vloss = running_vloss / len(testloader)\n",
        "            print(\"Avg losses\", avg_loss, avg_vloss)\n",
        "            running_loss = 0.0\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 86.94%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Validation Accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PgjFjxBZENE"
      },
      "source": [
        "#### 4. Make 2 variations of CNNs (using different convolutions or pooling parameters) and compare them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "EuYeJDj4zGTq"
      },
      "outputs": [],
      "source": [
        "# Variation 1\n",
        "class CNN_SmallerKernel(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN_SmallerKernel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)  # Smaller kernel\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)  # Consistent smaller kernel\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # Keeping consistent\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # Additional layer\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(128 * 1 * 1, 128)  # Adjusted for additional layer\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))  # Passing through the additional layer\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = CNN_SmallerKernel().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Mini-batch 40\n",
            "Avg losses 2.1336825788021088 1.6148829725897236\n",
            "Epoch 1, Mini-batch 80\n",
            "Avg losses 1.52433480322361 1.1496075133609165\n",
            "Epoch 1, Mini-batch 120\n",
            "Avg losses 1.263183844089508 0.9723088642594161\n",
            "Epoch 1, Mini-batch 160\n",
            "Avg losses 1.1077178508043288 0.9201601641193317\n",
            "Epoch 1, Mini-batch 200\n",
            "Avg losses 0.9802478283643723 0.81570476711176\n",
            "Epoch 1, Mini-batch 240\n",
            "Avg losses 0.9658822312951088 0.7572676459695123\n",
            "Epoch 1, Mini-batch 280\n",
            "Avg losses 0.840237733721733 0.8283275166514573\n",
            "Epoch 1, Mini-batch 320\n",
            "Avg losses 0.8322165817022323 0.7151842658307143\n",
            "Epoch 1, Mini-batch 360\n",
            "Avg losses 0.8173129454255104 0.7115288202170353\n",
            "Epoch 1, Mini-batch 400\n",
            "Avg losses 0.7928295254707336 0.6936248950897508\n",
            "Epoch 1, Mini-batch 440\n",
            "Avg losses 0.7459596335887909 0.7045896972060963\n",
            "Epoch 1, Mini-batch 480\n",
            "Avg losses 0.7627270698547364 0.6742308872520544\n",
            "Epoch 1, Mini-batch 520\n",
            "Avg losses 0.7518883749842644 0.6538464776269949\n",
            "Epoch 1, Mini-batch 560\n",
            "Avg losses 0.7342227786779404 0.6622672745376635\n",
            "Epoch 1, Mini-batch 600\n",
            "Avg losses 0.7271671094000339 0.6460089508894902\n",
            "Epoch 1, Mini-batch 640\n",
            "Avg losses 0.7434226535260677 0.6373428772589204\n",
            "Epoch 1, Mini-batch 680\n",
            "Avg losses 0.7428611144423485 0.6407363044608171\n",
            "Epoch 1, Mini-batch 720\n",
            "Avg losses 0.7065596379339695 0.6149057544720401\n",
            "Epoch 1, Mini-batch 760\n",
            "Avg losses 0.6593739725649357 0.6636408985040749\n",
            "Epoch 1, Mini-batch 800\n",
            "Avg losses 0.6956882558763027 0.6113148415164583\n",
            "Epoch 1, Mini-batch 840\n",
            "Avg losses 0.7011621713638305 0.6490381500523561\n",
            "Epoch 1, Mini-batch 880\n",
            "Avg losses 0.6994166195392608 0.5968626585735637\n",
            "Epoch 1, Mini-batch 920\n",
            "Avg losses 0.6574755899608136 0.6480696677781974\n",
            "Epoch 2, Mini-batch 40\n",
            "Avg losses 0.6683508709073067 0.5999485434620244\n",
            "Epoch 2, Mini-batch 80\n",
            "Avg losses 0.6397070720791816 0.6064020613576196\n",
            "Epoch 2, Mini-batch 120\n",
            "Avg losses 0.6248663447797298 0.5746654900395947\n",
            "Epoch 2, Mini-batch 160\n",
            "Avg losses 0.6273700520396233 0.5724936974276403\n",
            "Epoch 2, Mini-batch 200\n",
            "Avg losses 0.6332401879131794 0.5681052891312132\n",
            "Epoch 2, Mini-batch 240\n",
            "Avg losses 0.6318550854921341 0.556305747123281\n",
            "Epoch 2, Mini-batch 280\n",
            "Avg losses 0.6528913252055645 0.5918340992396045\n",
            "Epoch 2, Mini-batch 320\n",
            "Avg losses 0.6737175315618515 0.6385009508983345\n",
            "Epoch 2, Mini-batch 360\n",
            "Avg losses 0.6323347985744476 0.576903569660369\n",
            "Epoch 2, Mini-batch 400\n",
            "Avg losses 0.6367671981453895 0.6000962971122401\n",
            "Epoch 2, Mini-batch 440\n",
            "Avg losses 0.6112840913236142 0.5404232235471155\n",
            "Epoch 2, Mini-batch 480\n",
            "Avg losses 0.6019951358437539 0.5447895437668843\n",
            "Epoch 2, Mini-batch 520\n",
            "Avg losses 0.5819415166974068 0.5602891822909094\n",
            "Epoch 2, Mini-batch 560\n",
            "Avg losses 0.6087028235197067 0.5386692369060152\n",
            "Epoch 2, Mini-batch 600\n",
            "Avg losses 0.5743183791637421 0.5479135959391381\n",
            "Epoch 2, Mini-batch 640\n",
            "Avg losses 0.596821703761816 0.5276017432000227\n",
            "Epoch 2, Mini-batch 680\n",
            "Avg losses 0.5775195367634296 0.5222773062195748\n",
            "Epoch 2, Mini-batch 720\n",
            "Avg losses 0.6058980152010918 0.5115232422093677\n",
            "Epoch 2, Mini-batch 760\n",
            "Avg losses 0.573528727889061 0.48828241513792875\n",
            "Epoch 2, Mini-batch 800\n",
            "Avg losses 0.5829259663820267 0.511358537112072\n",
            "Epoch 2, Mini-batch 840\n",
            "Avg losses 0.5477950103580952 0.5553137232923204\n",
            "Epoch 2, Mini-batch 880\n",
            "Avg losses 0.5256001956760883 0.5764599996767227\n",
            "Epoch 2, Mini-batch 920\n",
            "Avg losses 0.5678845718502998 0.5288329179499559\n",
            "Epoch 3, Mini-batch 40\n",
            "Avg losses 0.5656296215951443 0.49104019961539347\n",
            "Epoch 3, Mini-batch 80\n",
            "Avg losses 0.53993284329772 0.4982720463518884\n",
            "Epoch 3, Mini-batch 120\n",
            "Avg losses 0.5403684981167316 0.4851044209519769\n",
            "Epoch 3, Mini-batch 160\n",
            "Avg losses 0.5338133379817009 0.47160518321262046\n",
            "Epoch 3, Mini-batch 200\n",
            "Avg losses 0.5602925516664982 0.48820703082783207\n",
            "Epoch 3, Mini-batch 240\n",
            "Avg losses 0.5387351430952549 0.46640291829018077\n",
            "Epoch 3, Mini-batch 280\n",
            "Avg losses 0.5477209128439426 0.4759714912836719\n",
            "Epoch 3, Mini-batch 320\n",
            "Avg losses 0.5287578850984573 0.47015757393685115\n",
            "Epoch 3, Mini-batch 360\n",
            "Avg losses 0.5571244813501834 0.5010026678158219\n",
            "Epoch 3, Mini-batch 400\n",
            "Avg losses 0.4990648701786995 0.48952560477955326\n",
            "Epoch 3, Mini-batch 440\n",
            "Avg losses 0.5107049830257893 0.4364937104427131\n",
            "Epoch 3, Mini-batch 480\n",
            "Avg losses 0.5302121587097645 0.45859909797929654\n",
            "Epoch 3, Mini-batch 520\n",
            "Avg losses 0.5090376473963261 0.4534963849623492\n",
            "Epoch 3, Mini-batch 560\n",
            "Avg losses 0.5099286772310734 0.4482327474720159\n",
            "Epoch 3, Mini-batch 600\n",
            "Avg losses 0.5186224974691868 0.449778884459453\n",
            "Epoch 3, Mini-batch 640\n",
            "Avg losses 0.5355662949383259 0.4322218921533815\n",
            "Epoch 3, Mini-batch 680\n",
            "Avg losses 0.5275554187595844 0.44391710021693237\n",
            "Epoch 3, Mini-batch 720\n",
            "Avg losses 0.5132034592330456 0.49862152508869295\n",
            "Epoch 3, Mini-batch 760\n",
            "Avg losses 0.5190714500844479 0.4456834648824801\n",
            "Epoch 3, Mini-batch 800\n",
            "Avg losses 0.477529726177454 0.4310904057921877\n",
            "Epoch 3, Mini-batch 840\n",
            "Avg losses 0.5234931036829948 0.4718376079182716\n",
            "Epoch 3, Mini-batch 880\n",
            "Avg losses 0.4877070941030979 0.4230846101121538\n",
            "Epoch 3, Mini-batch 920\n",
            "Avg losses 0.4675588883459568 0.4289430950287801\n",
            "Epoch 4, Mini-batch 40\n",
            "Avg losses 0.4853518471121788 0.4169979220742633\n",
            "Epoch 4, Mini-batch 80\n",
            "Avg losses 0.4992569275200367 0.3990699881391161\n",
            "Epoch 4, Mini-batch 120\n",
            "Avg losses 0.49868199303746225 0.4106930504748776\n",
            "Epoch 4, Mini-batch 160\n",
            "Avg losses 0.48668461926281453 0.4189676545607816\n",
            "Epoch 4, Mini-batch 200\n",
            "Avg losses 0.48433213829994204 0.4053518046049555\n",
            "Epoch 4, Mini-batch 240\n",
            "Avg losses 0.4876017764210701 0.4330702444929985\n",
            "Epoch 4, Mini-batch 280\n",
            "Avg losses 0.4681185409426689 0.4303625903691456\n",
            "Epoch 4, Mini-batch 320\n",
            "Avg losses 0.4816542699933052 0.4898818076416186\n",
            "Epoch 4, Mini-batch 360\n",
            "Avg losses 0.4992407836019993 0.41464281850939344\n",
            "Epoch 4, Mini-batch 400\n",
            "Avg losses 0.4709307551383972 0.40887646158789376\n",
            "Epoch 4, Mini-batch 440\n",
            "Avg losses 0.4586255967617035 0.42181752014691665\n",
            "Epoch 4, Mini-batch 480\n",
            "Avg losses 0.48620700240135195 0.39797670047753936\n",
            "Epoch 4, Mini-batch 520\n",
            "Avg losses 0.4657759204506874 0.3968808524737692\n",
            "Epoch 4, Mini-batch 560\n",
            "Avg losses 0.4548772670328617 0.40811798773753416\n",
            "Epoch 4, Mini-batch 600\n",
            "Avg losses 0.41801633723080156 0.3957836121130901\n",
            "Epoch 4, Mini-batch 640\n",
            "Avg losses 0.48294747620821 0.40781741755403533\n",
            "Epoch 4, Mini-batch 680\n",
            "Avg losses 0.43946013823151586 0.3969322984955113\n",
            "Epoch 4, Mini-batch 720\n",
            "Avg losses 0.46069231256842613 0.39924622369799645\n",
            "Epoch 4, Mini-batch 760\n",
            "Avg losses 0.5113706201314926 0.3878549198815777\n",
            "Epoch 4, Mini-batch 800\n",
            "Avg losses 0.4744654823094606 0.39692412962199775\n",
            "Epoch 4, Mini-batch 840\n",
            "Avg losses 0.462065090239048 0.40483550271790497\n",
            "Epoch 4, Mini-batch 880\n",
            "Avg losses 0.4610503017902374 0.4045555682698633\n",
            "Epoch 4, Mini-batch 920\n",
            "Avg losses 0.42648601680994036 0.40473883119738024\n",
            "Epoch 5, Mini-batch 40\n",
            "Avg losses 0.4544342175126076 0.38882461436994514\n",
            "Epoch 5, Mini-batch 80\n",
            "Avg losses 0.4346158929169178 0.38102265869735913\n",
            "Epoch 5, Mini-batch 120\n",
            "Avg losses 0.43173190802335737 0.3690183382884712\n",
            "Epoch 5, Mini-batch 160\n",
            "Avg losses 0.4269256889820099 0.42858737213596415\n",
            "Epoch 5, Mini-batch 200\n",
            "Avg losses 0.4357582785189152 0.398550864617536\n",
            "Epoch 5, Mini-batch 240\n",
            "Avg losses 0.4330927960574627 0.40059668043996116\n",
            "Epoch 5, Mini-batch 280\n",
            "Avg losses 0.4234659157693386 0.43023057244006235\n",
            "Epoch 5, Mini-batch 320\n",
            "Avg losses 0.44852695912122725 0.38714277848696255\n",
            "Epoch 5, Mini-batch 360\n",
            "Avg losses 0.444256366789341 0.4237421270768354\n",
            "Epoch 5, Mini-batch 400\n",
            "Avg losses 0.441783445328474 0.4140134972941344\n",
            "Epoch 5, Mini-batch 440\n",
            "Avg losses 0.4388395957648754 0.38671761903033897\n",
            "Epoch 5, Mini-batch 480\n",
            "Avg losses 0.4305942229926586 0.3743863798630465\n",
            "Epoch 5, Mini-batch 520\n",
            "Avg losses 0.4186954371631145 0.3707170627868859\n",
            "Epoch 5, Mini-batch 560\n",
            "Avg losses 0.4363182127475739 0.38196928951011344\n",
            "Epoch 5, Mini-batch 600\n",
            "Avg losses 0.4413634903728962 0.3808691223525697\n",
            "Epoch 5, Mini-batch 640\n",
            "Avg losses 0.4518955022096634 0.3618574311399156\n",
            "Epoch 5, Mini-batch 680\n",
            "Avg losses 0.4565606188029051 0.43071405304844973\n",
            "Epoch 5, Mini-batch 720\n",
            "Avg losses 0.4420696564018726 0.41445194554936354\n",
            "Epoch 5, Mini-batch 760\n",
            "Avg losses 0.4445178136229515 0.3633979243837344\n",
            "Epoch 5, Mini-batch 800\n",
            "Avg losses 0.44794905707240107 0.37232675009472355\n",
            "Epoch 5, Mini-batch 840\n",
            "Avg losses 0.43396355099976064 0.4046373300871272\n",
            "Epoch 5, Mini-batch 880\n",
            "Avg losses 0.43120962381362915 0.3625364840789965\n",
            "Epoch 5, Mini-batch 920\n",
            "Avg losses 0.45740377306938174 0.37288853260362226\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 40 == 39:    # Every 1000 mini-batches...\n",
        "            print(f'Epoch {epoch + 1}, Mini-batch {i + 1}')\n",
        "            # Check against the validation set\n",
        "            running_vloss = 0.0\n",
        "\n",
        "            # In evaluation mode some model specific operations can be omitted\n",
        "            model.train(False) # Switching to evaluation mode\n",
        "            for j, vdata in enumerate(testloader, 0):\n",
        "                vinputs, vlabels = vdata\n",
        "                voutputs = model(vinputs)\n",
        "                vloss = criterion(voutputs, vlabels)\n",
        "                running_vloss += vloss.item()\n",
        "\n",
        "            model.train(True) # Switching back to training mode\n",
        "            avg_loss = running_loss / 40\n",
        "            avg_vloss = running_vloss / len(testloader)\n",
        "            print(\"Avg losses\", avg_loss, avg_vloss)\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 86.64%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Validation Accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LtXmE54nzHLT"
      },
      "outputs": [],
      "source": [
        "# Variation 2\n",
        "class AdvancedCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AdvancedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
        "        self.drop1 = nn.Dropout2d(0.25)\n",
        "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
        "        self.fc3 = nn.Linear(in_features=120, out_features=num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(self.relu2(self.bn2(self.conv2(x))))\n",
        "        x = torch.flatten(x, start_dim=1)                   # Flatten the output for the FC layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.drop1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "advanced_model = AdvancedCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(advanced_model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\billi\\anaconda3\\envs\\hy673\\Lib\\site-packages\\torch\\nn\\functional.py:1347: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Mini-batch 40\n",
            "Avg losses 1.5242681324481964 0.8525329478986704\n",
            "Epoch 1, Mini-batch 80\n",
            "Avg losses 1.0370893865823745 0.7430852754100873\n",
            "Epoch 1, Mini-batch 120\n",
            "Avg losses 0.9235686242580414 0.7397893071174622\n",
            "Epoch 1, Mini-batch 160\n",
            "Avg losses 0.821924302726984 0.7614102650220227\n",
            "Epoch 1, Mini-batch 200\n",
            "Avg losses 0.8637741565704345 0.6847552131315705\n",
            "Epoch 1, Mini-batch 240\n",
            "Avg losses 0.8149684146046638 0.5975326478101646\n",
            "Epoch 1, Mini-batch 280\n",
            "Avg losses 0.808855478465557 0.6147933241668021\n",
            "Epoch 1, Mini-batch 320\n",
            "Avg losses 0.7487666964530945 0.5459070653672431\n",
            "Epoch 1, Mini-batch 360\n",
            "Avg losses 0.755778257548809 0.5877534498454658\n",
            "Epoch 1, Mini-batch 400\n",
            "Avg losses 0.6941879242658615 0.5739106987691989\n",
            "Epoch 1, Mini-batch 440\n",
            "Avg losses 0.6857024826109409 0.5758465718311868\n",
            "Epoch 1, Mini-batch 480\n",
            "Avg losses 0.7224613346159459 0.5802770230420835\n",
            "Epoch 1, Mini-batch 520\n",
            "Avg losses 0.6667289093136788 0.6553883734782031\n",
            "Epoch 1, Mini-batch 560\n",
            "Avg losses 0.6694584287703037 0.5966720588647636\n",
            "Epoch 1, Mini-batch 600\n",
            "Avg losses 0.6470530569553375 0.5233394638368278\n",
            "Epoch 1, Mini-batch 640\n",
            "Avg losses 0.6618524052202701 0.5855039863070105\n",
            "Epoch 1, Mini-batch 680\n",
            "Avg losses 0.6548742108047009 0.5361371678151902\n",
            "Epoch 1, Mini-batch 720\n",
            "Avg losses 0.6182942636311054 0.5954895025225961\n",
            "Epoch 1, Mini-batch 760\n",
            "Avg losses 0.6538758806884288 0.5317924658583987\n",
            "Epoch 1, Mini-batch 800\n",
            "Avg losses 0.6430403679609299 0.5040172518818242\n",
            "Epoch 1, Mini-batch 840\n",
            "Avg losses 0.6549496717751027 0.49064663327803276\n",
            "Epoch 1, Mini-batch 880\n",
            "Avg losses 0.6496258072555066 0.595292008986139\n",
            "Epoch 1, Mini-batch 920\n",
            "Avg losses 0.6198728792369366 0.4984943587688883\n",
            "Epoch 2, Mini-batch 40\n",
            "Avg losses 0.622129088640213 0.4707515351711565\n",
            "Epoch 2, Mini-batch 80\n",
            "Avg losses 0.6065294340252876 0.545179229063593\n",
            "Epoch 2, Mini-batch 120\n",
            "Avg losses 0.598249577730894 0.5821809846504479\n",
            "Epoch 2, Mini-batch 160\n",
            "Avg losses 0.6003455393016338 0.5290877445108572\n",
            "Epoch 2, Mini-batch 200\n",
            "Avg losses 0.5473857901990413 0.5759854254069602\n",
            "Epoch 2, Mini-batch 240\n",
            "Avg losses 0.6007399939000606 0.48517947212146345\n",
            "Epoch 2, Mini-batch 280\n",
            "Avg losses 0.5984953328967094 0.577201987527738\n",
            "Epoch 2, Mini-batch 320\n",
            "Avg losses 0.6261274576187134 0.5361248966614911\n",
            "Epoch 2, Mini-batch 360\n",
            "Avg losses 0.6242301695048809 0.5040164363991683\n",
            "Epoch 2, Mini-batch 400\n",
            "Avg losses 0.6057463318109513 0.49321068718934513\n",
            "Epoch 2, Mini-batch 440\n",
            "Avg losses 0.5842677094042301 0.46913618959818676\n",
            "Epoch 2, Mini-batch 480\n",
            "Avg losses 0.5833687871694565 0.4856394949802168\n",
            "Epoch 2, Mini-batch 520\n",
            "Avg losses 0.584896532446146 0.5046269865172683\n",
            "Epoch 2, Mini-batch 560\n",
            "Avg losses 0.5819155119359494 0.44894832306227106\n",
            "Epoch 2, Mini-batch 600\n",
            "Avg losses 0.5487883664667607 0.4671605398320848\n",
            "Epoch 2, Mini-batch 640\n",
            "Avg losses 0.583085010945797 0.4431366208632281\n",
            "Epoch 2, Mini-batch 680\n",
            "Avg losses 0.5644390098750591 0.491960031116844\n",
            "Epoch 2, Mini-batch 720\n",
            "Avg losses 0.5217415653169155 0.45059491124502415\n",
            "Epoch 2, Mini-batch 760\n",
            "Avg losses 0.5452509380877018 0.4415098255986621\n",
            "Epoch 2, Mini-batch 800\n",
            "Avg losses 0.5495784603059292 0.4838596610886276\n",
            "Epoch 2, Mini-batch 840\n",
            "Avg losses 0.5761896289885045 0.42262959859933064\n",
            "Epoch 2, Mini-batch 880\n",
            "Avg losses 0.5228051863610744 0.48156690122974904\n",
            "Epoch 2, Mini-batch 920\n",
            "Avg losses 0.5469505332410336 0.481993784760214\n",
            "Epoch 3, Mini-batch 40\n",
            "Avg losses 0.5821814455091954 0.4409378966328445\n",
            "Epoch 3, Mini-batch 80\n",
            "Avg losses 0.5103274121880531 0.42167879403776426\n",
            "Epoch 3, Mini-batch 120\n",
            "Avg losses 0.5048576653003692 0.44610017860770984\n",
            "Epoch 3, Mini-batch 160\n",
            "Avg losses 0.5169291336089372 0.4296425944490797\n",
            "Epoch 3, Mini-batch 200\n",
            "Avg losses 0.4992066606879234 0.46201509626428033\n",
            "Epoch 3, Mini-batch 240\n",
            "Avg losses 0.5537544511258602 0.4611637156670261\n",
            "Epoch 3, Mini-batch 280\n",
            "Avg losses 0.5344103813171387 0.4417102870288169\n",
            "Epoch 3, Mini-batch 320\n",
            "Avg losses 0.5450694695115089 0.4020710415711069\n",
            "Epoch 3, Mini-batch 360\n",
            "Avg losses 0.5221287049353123 0.42189326303400054\n",
            "Epoch 3, Mini-batch 400\n",
            "Avg losses 0.5396665453910827 0.4610652179475043\n",
            "Epoch 3, Mini-batch 440\n",
            "Avg losses 0.5380599685013294 0.42483301650566657\n",
            "Epoch 3, Mini-batch 480\n",
            "Avg losses 0.49788764491677284 0.48189087715118556\n",
            "Epoch 3, Mini-batch 520\n",
            "Avg losses 0.5385326609015465 0.38730197575441594\n",
            "Epoch 3, Mini-batch 560\n",
            "Avg losses 0.516803652793169 0.4866315960694271\n",
            "Epoch 3, Mini-batch 600\n",
            "Avg losses 0.5058067791163922 0.42499883624778434\n",
            "Epoch 3, Mini-batch 640\n",
            "Avg losses 0.5179882042109967 0.40865699491303437\n",
            "Epoch 3, Mini-batch 680\n",
            "Avg losses 0.524142251163721 0.4124909076531222\n",
            "Epoch 3, Mini-batch 720\n",
            "Avg losses 0.5365148685872555 0.40383015667936606\n",
            "Epoch 3, Mini-batch 760\n",
            "Avg losses 0.5207323208451271 0.3967267284347753\n",
            "Epoch 3, Mini-batch 800\n",
            "Avg losses 0.5291235506534576 0.43575408191058285\n",
            "Epoch 3, Mini-batch 840\n",
            "Avg losses 0.5332329265773297 0.40889066011662695\n",
            "Epoch 3, Mini-batch 880\n",
            "Avg losses 0.5160415217280387 0.4218020591006917\n",
            "Epoch 3, Mini-batch 920\n",
            "Avg losses 0.5013662233948708 0.4012676189849331\n",
            "Epoch 4, Mini-batch 40\n",
            "Avg losses 0.47998842522501944 0.4309153249309321\n",
            "Epoch 4, Mini-batch 80\n",
            "Avg losses 0.516145084053278 0.38572708607479267\n",
            "Epoch 4, Mini-batch 120\n",
            "Avg losses 0.5214711092412472 0.3705063927325474\n",
            "Epoch 4, Mini-batch 160\n",
            "Avg losses 0.4608992043882608 0.4390391715962416\n",
            "Epoch 4, Mini-batch 200\n",
            "Avg losses 0.49044410735368726 0.3952225253080866\n",
            "Epoch 4, Mini-batch 240\n",
            "Avg losses 0.5116938009858132 0.4259399371162342\n",
            "Epoch 4, Mini-batch 280\n",
            "Avg losses 0.4941778860986233 0.37471767908828274\n",
            "Epoch 4, Mini-batch 320\n",
            "Avg losses 0.4645227208733559 0.38976134340854207\n",
            "Epoch 4, Mini-batch 360\n",
            "Avg losses 0.5330909974873066 0.42392547039469336\n",
            "Epoch 4, Mini-batch 400\n",
            "Avg losses 0.5199921362102031 0.3777840161209653\n",
            "Epoch 4, Mini-batch 440\n",
            "Avg losses 0.4799816831946373 0.402051653641804\n",
            "Epoch 4, Mini-batch 480\n",
            "Avg losses 0.4960523948073387 0.3916285075010008\n",
            "Epoch 4, Mini-batch 520\n",
            "Avg losses 0.49262252524495126 0.40508382933534637\n",
            "Epoch 4, Mini-batch 560\n",
            "Avg losses 0.5014429099857807 0.3790346826337705\n",
            "Epoch 4, Mini-batch 600\n",
            "Avg losses 0.4740375727415085 0.37193413050311386\n",
            "Epoch 4, Mini-batch 640\n",
            "Avg losses 0.48664063438773153 0.386058531559197\n",
            "Epoch 4, Mini-batch 680\n",
            "Avg losses 0.5036519475281238 0.3642292241002344\n",
            "Epoch 4, Mini-batch 720\n",
            "Avg losses 0.48235287256538867 0.4460051872168377\n",
            "Epoch 4, Mini-batch 760\n",
            "Avg losses 0.48336007073521614 0.3844908088635487\n",
            "Epoch 4, Mini-batch 800\n",
            "Avg losses 0.4572580136358738 0.4281149443927085\n",
            "Epoch 4, Mini-batch 840\n",
            "Avg losses 0.4933651708066463 0.39135416943556184\n",
            "Epoch 4, Mini-batch 880\n",
            "Avg losses 0.5031488299369812 0.37840020030167454\n",
            "Epoch 4, Mini-batch 920\n",
            "Avg losses 0.49375817030668256 0.40967079617415264\n",
            "Epoch 5, Mini-batch 40\n",
            "Avg losses 0.4455251656472683 0.3747836593419883\n",
            "Epoch 5, Mini-batch 80\n",
            "Avg losses 0.45301179923117163 0.4128956745384605\n",
            "Epoch 5, Mini-batch 120\n",
            "Avg losses 0.4914753094315529 0.36258530531339583\n",
            "Epoch 5, Mini-batch 160\n",
            "Avg losses 0.4710127241909504 0.35915407044872355\n",
            "Epoch 5, Mini-batch 200\n",
            "Avg losses 0.43653811924159525 0.4011909666524571\n",
            "Epoch 5, Mini-batch 240\n",
            "Avg losses 0.4775091581046581 0.3763185712941893\n",
            "Epoch 5, Mini-batch 280\n",
            "Avg losses 0.4734596528112888 0.3968375895623189\n",
            "Epoch 5, Mini-batch 320\n",
            "Avg losses 0.4568965211510658 0.3648814441292149\n",
            "Epoch 5, Mini-batch 360\n",
            "Avg losses 0.48479233384132386 0.4140956713135835\n",
            "Epoch 5, Mini-batch 400\n",
            "Avg losses 0.4632658906280994 0.3560446250685461\n",
            "Epoch 5, Mini-batch 440\n",
            "Avg losses 0.4843827597796917 0.4017630087532056\n",
            "Epoch 5, Mini-batch 480\n",
            "Avg losses 0.46931702792644503 0.38366637393167824\n",
            "Epoch 5, Mini-batch 520\n",
            "Avg losses 0.4525588147342205 0.3865358614048381\n",
            "Epoch 5, Mini-batch 560\n",
            "Avg losses 0.4741483062505722 0.35971045152396913\n",
            "Epoch 5, Mini-batch 600\n",
            "Avg losses 0.45384656004607676 0.3384040997950894\n",
            "Epoch 5, Mini-batch 640\n",
            "Avg losses 0.44787884391844274 0.34634101590153515\n",
            "Epoch 5, Mini-batch 680\n",
            "Avg losses 0.4623636394739151 0.3680944083033094\n",
            "Epoch 5, Mini-batch 720\n",
            "Avg losses 0.47873291149735453 0.3830032316362782\n",
            "Epoch 5, Mini-batch 760\n",
            "Avg losses 0.4594745498150587 0.3602153369860285\n",
            "Epoch 5, Mini-batch 800\n",
            "Avg losses 0.46688931733369826 0.3330150298347139\n",
            "Epoch 5, Mini-batch 840\n",
            "Avg losses 0.47868338599801064 0.36362710319886543\n",
            "Epoch 5, Mini-batch 880\n",
            "Avg losses 0.4527022406458855 0.36668614824866036\n",
            "Epoch 5, Mini-batch 920\n",
            "Avg losses 0.44670613035559653 0.3756118640778171\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = advanced_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 40 == 39:    # Every 1000 mini-batches...\n",
        "            print(f'Epoch {epoch + 1}, Mini-batch {i + 1}')\n",
        "            # Check against the validation set\n",
        "            running_vloss = 0.0\n",
        "\n",
        "            # In evaluation mode some model specific operations can be omitted\n",
        "            advanced_model.train(False) # Switching to evaluation mode\n",
        "            for j, vdata in enumerate(testloader, 0):\n",
        "                vinputs, vlabels = vdata\n",
        "                voutputs = advanced_model(vinputs)\n",
        "                vloss = criterion(voutputs, vlabels)\n",
        "                running_vloss += vloss.item()\n",
        "\n",
        "            advanced_model.train(True) # Switching back to training mode\n",
        "            avg_loss = running_loss / 40\n",
        "            avg_vloss = running_vloss / len(testloader)\n",
        "            print(\"Avg losses\", avg_loss, avg_vloss)\n",
        "            running_loss = 0.0\n",
        "\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 85.91%\n"
          ]
        }
      ],
      "source": [
        "advanced_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = advanced_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Validation Accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Increase the number of Layers of the CNN (the number of convolutions followed by pooling layers) and observe what happens, in terms of the progress of the training and validation losses and the final model accuracies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImprovedAdvancedCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ImprovedAdvancedCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU()  # Re-use the same ReLU\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Re-use the same MaxPool\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.fc1 = nn.Linear(in_features=128*3*3, out_features=256)\n",
        "        self.drop = nn.Dropout(0.3)  # Adjust dropout rate\n",
        "        self.fc2 = nn.Linear(in_features=256, out_features=num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(self.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(self.relu(self.bn3(self.conv3(x))))\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.drop(self.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_cnn = ImprovedAdvancedCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(new_cnn.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Mini-batch 40\n",
            "Avg losses 1.4969915300607681 0.8798978833635901\n",
            "Epoch 1, Mini-batch 80\n",
            "Avg losses 0.9856502771377563 0.6902722843513367\n",
            "Epoch 1, Mini-batch 120\n",
            "Avg losses 0.8845923230051994 0.6302734810835237\n",
            "Epoch 1, Mini-batch 160\n",
            "Avg losses 0.7913389012217522 0.6760299198187081\n",
            "Epoch 1, Mini-batch 200\n",
            "Avg losses 0.7503109738230705 0.6664535744934325\n",
            "Epoch 1, Mini-batch 240\n",
            "Avg losses 0.7579026475548745 0.6771428006090177\n",
            "Epoch 1, Mini-batch 280\n",
            "Avg losses 0.6772193476557732 0.6033302856858369\n",
            "Epoch 1, Mini-batch 320\n",
            "Avg losses 0.7194433897733689 0.5365123435570176\n",
            "Epoch 1, Mini-batch 360\n",
            "Avg losses 0.6532005243003368 0.5194409736402475\n",
            "Epoch 1, Mini-batch 400\n",
            "Avg losses 0.6554859504103661 0.5116660556975444\n",
            "Epoch 1, Mini-batch 440\n",
            "Avg losses 0.6131355248391628 0.5597237893350565\n",
            "Epoch 1, Mini-batch 480\n",
            "Avg losses 0.6180731110274792 0.4932280687769507\n",
            "Epoch 1, Mini-batch 520\n",
            "Avg losses 0.6396568424999713 0.48973855660979154\n",
            "Epoch 1, Mini-batch 560\n",
            "Avg losses 0.5884454570710659 0.5692256516332079\n",
            "Epoch 1, Mini-batch 600\n",
            "Avg losses 0.5890150338411331 0.5396664377990043\n",
            "Epoch 1, Mini-batch 640\n",
            "Avg losses 0.5531519778072834 0.4874236373954518\n",
            "Epoch 1, Mini-batch 680\n",
            "Avg losses 0.605070598423481 0.5122615639001701\n",
            "Epoch 1, Mini-batch 720\n",
            "Avg losses 0.5821650721132755 0.466965531562544\n",
            "Epoch 1, Mini-batch 760\n",
            "Avg losses 0.5742594666779042 0.5112480675908411\n",
            "Epoch 1, Mini-batch 800\n",
            "Avg losses 0.558754027634859 0.4371444558262066\n",
            "Epoch 1, Mini-batch 840\n",
            "Avg losses 0.5881754763424396 0.4812353722229125\n",
            "Epoch 1, Mini-batch 880\n",
            "Avg losses 0.5441417194902897 0.4474163996945521\n",
            "Epoch 1, Mini-batch 920\n",
            "Avg losses 0.5307543613016605 0.44721254782312236\n",
            "Epoch 2, Mini-batch 40\n",
            "Avg losses 0.5242198057472706 0.43660080119682726\n",
            "Epoch 2, Mini-batch 80\n",
            "Avg losses 0.5557426109910011 0.44892521715088257\n",
            "Epoch 2, Mini-batch 120\n",
            "Avg losses 0.4925445966422558 0.47378737645544067\n",
            "Epoch 2, Mini-batch 160\n",
            "Avg losses 0.5381553120911121 0.4298996476420931\n",
            "Epoch 2, Mini-batch 200\n",
            "Avg losses 0.5199075557291508 0.42396212990876214\n",
            "Epoch 2, Mini-batch 240\n",
            "Avg losses 0.524576322734356 0.4472907234908669\n",
            "Epoch 2, Mini-batch 280\n",
            "Avg losses 0.4914270907640457 0.4221851886457698\n",
            "Epoch 2, Mini-batch 320\n",
            "Avg losses 0.5081906236708165 0.4566620324447656\n",
            "Epoch 2, Mini-batch 360\n",
            "Avg losses 0.5058036014437676 0.40424277951383286\n",
            "Epoch 2, Mini-batch 400\n",
            "Avg losses 0.5068361818790436 0.416527720773296\n",
            "Epoch 2, Mini-batch 440\n",
            "Avg losses 0.501939332485199 0.38856725437436135\n",
            "Epoch 2, Mini-batch 480\n",
            "Avg losses 0.4870403937995434 0.4491564013585923\n",
            "Epoch 2, Mini-batch 520\n",
            "Avg losses 0.5171451881527901 0.40478768498654577\n",
            "Epoch 2, Mini-batch 560\n",
            "Avg losses 0.5285009577870369 0.43682020997545523\n",
            "Epoch 2, Mini-batch 600\n",
            "Avg losses 0.5178450755774975 0.4133070591528704\n",
            "Epoch 2, Mini-batch 640\n",
            "Avg losses 0.4881459340453148 0.4159799386171778\n",
            "Epoch 2, Mini-batch 680\n",
            "Avg losses 0.46741089075803754 0.4233604212095783\n",
            "Epoch 2, Mini-batch 720\n",
            "Avg losses 0.476632796600461 0.3900822821980829\n",
            "Epoch 2, Mini-batch 760\n",
            "Avg losses 0.5001778900623322 0.3775715847873384\n",
            "Epoch 2, Mini-batch 800\n",
            "Avg losses 0.45810941234230995 0.3869019170665437\n",
            "Epoch 2, Mini-batch 840\n",
            "Avg losses 0.49407732784748076 0.39489118992143374\n",
            "Epoch 2, Mini-batch 880\n",
            "Avg losses 0.4659915819764137 0.3568341438272956\n",
            "Epoch 2, Mini-batch 920\n",
            "Avg losses 0.4515378218144178 0.37265652664907417\n",
            "Epoch 3, Mini-batch 40\n",
            "Avg losses 0.4816784955561161 0.36878807510539985\n",
            "Epoch 3, Mini-batch 80\n",
            "Avg losses 0.456298790872097 0.37794306091252405\n",
            "Epoch 3, Mini-batch 120\n",
            "Avg losses 0.47375707775354386 0.3774171882564095\n",
            "Epoch 3, Mini-batch 160\n",
            "Avg losses 0.4582195580005646 0.36234323258043094\n",
            "Epoch 3, Mini-batch 200\n",
            "Avg losses 0.44406651332974434 0.3673309880267283\n",
            "Epoch 3, Mini-batch 240\n",
            "Avg losses 0.4606130201369524 0.3466614131240328\n",
            "Epoch 3, Mini-batch 280\n",
            "Avg losses 0.4767486810684204 0.3513903757379313\n",
            "Epoch 3, Mini-batch 320\n",
            "Avg losses 0.4240469615906477 0.3334515987877633\n",
            "Epoch 3, Mini-batch 360\n",
            "Avg losses 0.44518006034195423 0.3754919510643194\n",
            "Epoch 3, Mini-batch 400\n",
            "Avg losses 0.4535730630159378 0.3768335602655532\n",
            "Epoch 3, Mini-batch 440\n",
            "Avg losses 0.45032323971390725 0.42771713307518866\n",
            "Epoch 3, Mini-batch 480\n",
            "Avg losses 0.5003232546150684 0.3432481080578391\n",
            "Epoch 3, Mini-batch 520\n",
            "Avg losses 0.440817866101861 0.3472161442041397\n",
            "Epoch 3, Mini-batch 560\n",
            "Avg losses 0.4391304336488247 0.3692114967259632\n",
            "Epoch 3, Mini-batch 600\n",
            "Avg losses 0.4507560823112726 0.3730657958680657\n",
            "Epoch 3, Mini-batch 640\n",
            "Avg losses 0.38843623325228693 0.33409718599668736\n",
            "Epoch 3, Mini-batch 680\n",
            "Avg losses 0.450623494386673 0.3478284375208199\n",
            "Epoch 3, Mini-batch 720\n",
            "Avg losses 0.4500566504895687 0.32851436439972775\n",
            "Epoch 3, Mini-batch 760\n",
            "Avg losses 0.4410347413271666 0.3448229792771066\n",
            "Epoch 3, Mini-batch 800\n",
            "Avg losses 0.43848027363419534 0.3219954944245375\n",
            "Epoch 3, Mini-batch 840\n",
            "Avg losses 0.44421962201595305 0.3672167466609341\n",
            "Epoch 3, Mini-batch 880\n",
            "Avg losses 0.42818086594343185 0.34185971234254775\n",
            "Epoch 3, Mini-batch 920\n",
            "Avg losses 0.4224027045071125 0.32606787894182143\n",
            "Epoch 4, Mini-batch 40\n",
            "Avg losses 0.4360565938055515 0.3338646736399383\n",
            "Epoch 4, Mini-batch 80\n",
            "Avg losses 0.4368272162973881 0.36445743239419476\n",
            "Epoch 4, Mini-batch 120\n",
            "Avg losses 0.4126576866954565 0.32989210227302684\n",
            "Epoch 4, Mini-batch 160\n",
            "Avg losses 0.4209317918866873 0.3591805446869249\n",
            "Epoch 4, Mini-batch 200\n",
            "Avg losses 0.41568815931677816 0.31933508433733776\n",
            "Epoch 4, Mini-batch 240\n",
            "Avg losses 0.42019473277032376 0.3393270904850808\n",
            "Epoch 4, Mini-batch 280\n",
            "Avg losses 0.4427238292992115 0.3260065562501075\n",
            "Epoch 4, Mini-batch 320\n",
            "Avg losses 0.40872874967753886 0.34040053767763123\n",
            "Epoch 4, Mini-batch 360\n",
            "Avg losses 0.41720767840743067 0.33897902821279635\n",
            "Epoch 4, Mini-batch 400\n",
            "Avg losses 0.42945273742079737 0.34878278134544943\n",
            "Epoch 4, Mini-batch 440\n",
            "Avg losses 0.3960462588816881 0.33256419278254173\n",
            "Epoch 4, Mini-batch 480\n",
            "Avg losses 0.4063977118581533 0.33691401025102397\n",
            "Epoch 4, Mini-batch 520\n",
            "Avg losses 0.4204039596021175 0.3199191906839419\n",
            "Epoch 4, Mini-batch 560\n",
            "Avg losses 0.43328600823879243 0.32288263837812814\n",
            "Epoch 4, Mini-batch 600\n",
            "Avg losses 0.4087146416306496 0.312789638330982\n",
            "Epoch 4, Mini-batch 640\n",
            "Avg losses 0.4306886989623308 0.33173913513399234\n",
            "Epoch 4, Mini-batch 680\n",
            "Avg losses 0.42538394778966904 0.3217358255557194\n",
            "Epoch 4, Mini-batch 720\n",
            "Avg losses 0.40223639607429507 0.3169737664662349\n",
            "Epoch 4, Mini-batch 760\n",
            "Avg losses 0.3924720145761967 0.3207613392525418\n",
            "Epoch 4, Mini-batch 800\n",
            "Avg losses 0.40174512304365634 0.35066684136155307\n",
            "Epoch 4, Mini-batch 840\n",
            "Avg losses 0.4079871572554111 0.33262838750698004\n",
            "Epoch 4, Mini-batch 880\n",
            "Avg losses 0.4018106147646904 0.3220226668343423\n",
            "Epoch 4, Mini-batch 920\n",
            "Avg losses 0.4310002002865076 0.32614135552363793\n",
            "Epoch 5, Mini-batch 40\n",
            "Avg losses 0.4334203217178583 0.33067253706561534\n",
            "Epoch 5, Mini-batch 80\n",
            "Avg losses 0.41132774502038955 0.3224852449100488\n",
            "Epoch 5, Mini-batch 120\n",
            "Avg losses 0.3842919960618019 0.30289615752400867\n",
            "Epoch 5, Mini-batch 160\n",
            "Avg losses 0.4213488485664129 0.3166799782567723\n",
            "Epoch 5, Mini-batch 200\n",
            "Avg losses 0.3860133238136768 0.31664450272063543\n",
            "Epoch 5, Mini-batch 240\n",
            "Avg losses 0.3983054168522358 0.31073488570322655\n",
            "Epoch 5, Mini-batch 280\n",
            "Avg losses 0.39046285711228845 0.3182306855347506\n",
            "Epoch 5, Mini-batch 320\n",
            "Avg losses 0.3874956492334604 0.3270929374607505\n",
            "Epoch 5, Mini-batch 360\n",
            "Avg losses 0.42921577841043473 0.3160371528879093\n",
            "Epoch 5, Mini-batch 400\n",
            "Avg losses 0.39550915770232675 0.3343903824781916\n",
            "Epoch 5, Mini-batch 440\n",
            "Avg losses 0.3911921802908182 0.3177404685574732\n",
            "Epoch 5, Mini-batch 480\n",
            "Avg losses 0.4144167724996805 0.30346403555695417\n",
            "Epoch 5, Mini-batch 520\n",
            "Avg losses 0.381162728369236 0.3076081099403892\n",
            "Epoch 5, Mini-batch 560\n",
            "Avg losses 0.3917914856225252 0.3536731816685883\n",
            "Epoch 5, Mini-batch 600\n",
            "Avg losses 0.42760527282953265 0.3038324959528674\n",
            "Epoch 5, Mini-batch 640\n",
            "Avg losses 0.37138821817934514 0.32053763511928784\n",
            "Epoch 5, Mini-batch 680\n",
            "Avg losses 0.4035045452415943 0.32158937627912326\n",
            "Epoch 5, Mini-batch 720\n",
            "Avg losses 0.35877915024757384 0.3080584067068282\n",
            "Epoch 5, Mini-batch 760\n",
            "Avg losses 0.37871848307549955 0.3025639172002768\n",
            "Epoch 5, Mini-batch 800\n",
            "Avg losses 0.4105688720941544 0.32414758129484333\n",
            "Epoch 5, Mini-batch 840\n",
            "Avg losses 0.36771500259637835 0.31195176373811284\n",
            "Epoch 5, Mini-batch 880\n",
            "Avg losses 0.37315436005592345 0.2990449514643402\n",
            "Epoch 5, Mini-batch 920\n",
            "Avg losses 0.37237070761621 0.3026592451960418\n",
            "Epoch 6, Mini-batch 40\n",
            "Avg losses 0.3894745759665966 0.3254387856099256\n",
            "Epoch 6, Mini-batch 80\n",
            "Avg losses 0.383066513389349 0.32254553553025433\n",
            "Epoch 6, Mini-batch 120\n",
            "Avg losses 0.3632592737674713 0.309221492688747\n",
            "Epoch 6, Mini-batch 160\n",
            "Avg losses 0.3907458957284689 0.3031774227786216\n",
            "Epoch 6, Mini-batch 200\n",
            "Avg losses 0.3791403669863939 0.2945047187482476\n",
            "Epoch 6, Mini-batch 240\n",
            "Avg losses 0.3670856706798077 0.31678123886038545\n",
            "Epoch 6, Mini-batch 280\n",
            "Avg losses 0.3868887729942799 0.31907437419056134\n",
            "Epoch 6, Mini-batch 320\n",
            "Avg losses 0.36716178357601165 0.3397186505282001\n",
            "Epoch 6, Mini-batch 360\n",
            "Avg losses 0.33920919317752124 0.3145924060113111\n",
            "Epoch 6, Mini-batch 400\n",
            "Avg losses 0.3824998799711466 0.2998969821603435\n",
            "Epoch 6, Mini-batch 440\n",
            "Avg losses 0.37112052999436856 0.30047425836514513\n",
            "Epoch 6, Mini-batch 480\n",
            "Avg losses 0.3862998716533184 0.30781951992754725\n",
            "Epoch 6, Mini-batch 520\n",
            "Avg losses 0.35193534307181834 0.3036956157843778\n",
            "Epoch 6, Mini-batch 560\n",
            "Avg losses 0.3937213081866503 0.3105760114682708\n",
            "Epoch 6, Mini-batch 600\n",
            "Avg losses 0.39800319001078605 0.29534496964922374\n",
            "Epoch 6, Mini-batch 640\n",
            "Avg losses 0.39073716178536416 0.3188184611736589\n",
            "Epoch 6, Mini-batch 680\n",
            "Avg losses 0.3710803594440222 0.294976742878841\n",
            "Epoch 6, Mini-batch 720\n",
            "Avg losses 0.350842684134841 0.31510971643173014\n",
            "Epoch 6, Mini-batch 760\n",
            "Avg losses 0.3668274417519569 0.3102774879640075\n",
            "Epoch 6, Mini-batch 800\n",
            "Avg losses 0.38744327016174795 0.3026830285407935\n",
            "Epoch 6, Mini-batch 840\n",
            "Avg losses 0.39306013099849224 0.3067152666248334\n",
            "Epoch 6, Mini-batch 880\n",
            "Avg losses 0.37829962782561777 0.29819967094690175\n",
            "Epoch 6, Mini-batch 920\n",
            "Avg losses 0.36303142793476584 0.3002098810141254\n",
            "Epoch 7, Mini-batch 40\n",
            "Avg losses 0.36552359387278555 0.2841501113051062\n",
            "Epoch 7, Mini-batch 80\n",
            "Avg losses 0.36030155681073667 0.29623584105235756\n",
            "Epoch 7, Mini-batch 120\n",
            "Avg losses 0.36362759210169315 0.301906377504206\n",
            "Epoch 7, Mini-batch 160\n",
            "Avg losses 0.34625001698732377 0.2853047690668683\n",
            "Epoch 7, Mini-batch 200\n",
            "Avg losses 0.3619365103542805 0.29067717649184976\n",
            "Epoch 7, Mini-batch 240\n",
            "Avg losses 0.37337427884340285 0.30948517144105997\n",
            "Epoch 7, Mini-batch 280\n",
            "Avg losses 0.36141241528093815 0.2804509085739494\n",
            "Epoch 7, Mini-batch 320\n",
            "Avg losses 0.3420407649129629 0.28658499658867054\n",
            "Epoch 7, Mini-batch 360\n",
            "Avg losses 0.3888072069734335 0.28479042748926553\n",
            "Epoch 7, Mini-batch 400\n",
            "Avg losses 0.3566825095564127 0.2942798135766558\n",
            "Epoch 7, Mini-batch 440\n",
            "Avg losses 0.36448929980397227 0.2876517730438785\n",
            "Epoch 7, Mini-batch 480\n",
            "Avg losses 0.3558387067168951 0.2846934015204193\n",
            "Epoch 7, Mini-batch 520\n",
            "Avg losses 0.3817741222679615 0.2957936007126122\n",
            "Epoch 7, Mini-batch 560\n",
            "Avg losses 0.36355649419128894 0.2980403776286514\n",
            "Epoch 7, Mini-batch 600\n",
            "Avg losses 0.3721838667988777 0.29555085989510177\n",
            "Epoch 7, Mini-batch 640\n",
            "Avg losses 0.32538113854825496 0.30826624620492293\n",
            "Epoch 7, Mini-batch 680\n",
            "Avg losses 0.3828666754066944 0.28130136620087226\n",
            "Epoch 7, Mini-batch 720\n",
            "Avg losses 0.3591589882969856 0.2874444656690974\n",
            "Epoch 7, Mini-batch 760\n",
            "Avg losses 0.3394107215106487 0.2909249063035485\n",
            "Epoch 7, Mini-batch 800\n",
            "Avg losses 0.3769090313464403 0.2849549150485901\n",
            "Epoch 7, Mini-batch 840\n",
            "Avg losses 0.3781993702054024 0.2873985333617326\n",
            "Epoch 7, Mini-batch 880\n",
            "Avg losses 0.37391138896346093 0.28064594308661805\n",
            "Epoch 7, Mini-batch 920\n",
            "Avg losses 0.3804738488048315 0.28876950606039375\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 7\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = new_cnn(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        if i % 40 == 39:    # Every 1000 mini-batches...\n",
        "            print(f'Epoch {epoch + 1}, Mini-batch {i + 1}')\n",
        "            # Check against the validation set\n",
        "            running_vloss = 0.0\n",
        "\n",
        "            # In evaluation mode some model specific operations can be omitted\n",
        "            new_cnn.train(False) # Switching to evaluation mode\n",
        "            for j, vdata in enumerate(testloader, 0):\n",
        "                vinputs, vlabels = vdata\n",
        "                voutputs = new_cnn(vinputs)\n",
        "                vloss = criterion(voutputs, vlabels)\n",
        "                running_vloss += vloss.item()\n",
        "\n",
        "            new_cnn.train(True) # Switching back to training mode\n",
        "            avg_loss = running_loss / 40\n",
        "            avg_vloss = running_vloss / len(testloader)\n",
        "            print(\"Avg losses\", avg_loss, avg_vloss)\n",
        "            running_loss = 0.0\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "if not os.path.exists('./Models'):\n",
        "    os.makedirs('./Models')\n",
        "\n",
        "torch.save(new_cnn.state_dict(), './Models/model_weights.pth')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 89.92%\n"
          ]
        }
      ],
      "source": [
        "new_cnn.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = new_cnn(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Validation Accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the details you've provided, here's a comparison and analysis of the original CustomCNN model and its two variations when trained on a dataset (assumed to be similar to FashionMNIST given the context and structure of the networks) for 5 epochs using a CrossEntropyLoss and Adam optimizer.\n",
        "\n",
        "### Original CustomCNN Model\n",
        "- **Architecture**: Consists of three convolutional layers with increasing channel sizes (16, 32, 64) and kernel size 5, followed by two fully connected layers. It uses MaxPooling for downsampling.\n",
        "- **Validation Accuracy**: 86.94%\n",
        "- **Observations**:\n",
        "  - This model provides a solid baseline performance on the dataset.\n",
        "  - The larger kernel size in the initial layers may help in capturing broader features in the image early in the network.\n",
        "  - The sequential increase in channel size is a common pattern for deepening CNNs, allowing for more complex feature extraction in deeper layers.\n",
        "\n",
        "### Variation 1: CNN_SmallerKernel\n",
        "- **Architecture**: Introduces smaller kernels (3x3) across four convolutional layers and an additional convolutional layer compared to the baseline, with the final layer having 128 channels. The fully connected layer is adjusted to match the output of the additional convolutional layer.\n",
        "- **Validation Accuracy**: 86.64%\n",
        "- **Observations**:\n",
        "  - The slight decrease in accuracy compared to the baseline could be attributed to the network's increased depth, potentially requiring more epochs to fully converge.\n",
        "  - Smaller kernels and an additional convolutional layer increase the model's capacity to learn finer, more localized features but may also slightly increase the model's complexity and computational demand.\n",
        "  - The model's performance indicates that the benefits of additional depth and smaller kernels did not significantly outweigh the baseline model's configuration within the same training duration.\n",
        "\n",
        "### Variation 2: AdvancedCNN\n",
        "- **Architecture**: Incorporates Batch Normalization and ReLU activations explicitly in its architecture with two convolutional layers followed by a sequence of fully connected layers, including a Dropout layer for regularization.\n",
        "- **Validation Accuracy**: 85.91%\n",
        "- **Observations**:\n",
        "  - The introduction of Batch Normalization aims to stabilize learning and accelerate convergence by normalizing the input to each activation layer.\n",
        "  - Dropout is included to combat overfitting by randomly zeroing some of the layer's outputs during training.\n",
        "  - Despite these theoretically beneficial architectural choices, the model underperforms slightly compared to both the baseline and Variation 1. This could be due to various factors such as the need for more training epochs for this more complex model to converge or an imbalance in the model's architecture that does not align perfectly with the dataset's characteristics.\n",
        "\n",
        "### Overall Observations\n",
        "- **Depth and Complexity**: Increasing model complexity either by adding more layers (Variation 1) or introducing regularization and normalization techniques (Variation 2) does not always guarantee better performance, especially within a limited number of training epochs. Both variations showed slightly lower performance compared to the original model.\n",
        "- **Kernel Size**: The choice of kernel size impacts how the model learns and extracts features from images. While smaller kernels allow the model to learn finer details, they may require the model to be deeper (more layers) to capture global features effectively.\n",
        "- **Regularization and Normalization**: The introduction of Batch Normalization and Dropout in Variation 2 is aimed at improving training stability and reducing overfitting but also adds to the model's training dynamics, possibly requiring adjustments in training strategy.\n",
        "\n",
        "In conclusion, while both variations introduce theoretically beneficial changes to the architecture, neither outperforms the original CustomCNN model in the context of this specific task and training setup. This outcome highlights the importance of balancing model complexity with the available data and computational resources, and the necessity of tailoring the architecture and training process to the specifics of the task at hand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1vGCvngZJXv"
      },
      "source": [
        "#### 6. Visualize some of the Feature Maps and Convolution Kernels that you find interesting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WaOHgiDtzHyY"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ImprovedAdvancedCNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU()\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=1152, out_features=256, bias=True)\n",
              "  (drop): Dropout(p=0.3, inplace=False)\n",
              "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ImprovedAdvancedCNN()\n",
        "model.load_state_dict(torch.load(\"./Models/model_weights.pth\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "images, _ = next(iter(trainloader))\n",
        "image = images[0].unsqueeze(0)  # Add batch dimension for a single image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 32 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def visualize_kernels(layer):\n",
        "    kernels = layer.weight.data.cpu().numpy()\n",
        "    kernels = (kernels - kernels.min()) / (kernels.max() - kernels.min())  # Normalize\n",
        "\n",
        "    num_kernels = kernels.shape[0]\n",
        "    num_cols = 8  # Or any number you prefer\n",
        "    num_rows = num_kernels // num_cols + (num_kernels % num_cols != 0)\n",
        "\n",
        "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(num_cols, num_rows))\n",
        "    for i, ax in enumerate(axs.flat):\n",
        "        if i < num_kernels:\n",
        "            kernel = kernels[i, 0]  # Assuming grayscale (1 channel)\n",
        "            ax.imshow(kernel, cmap=\"gray\")\n",
        "            ax.axis('off')\n",
        "        else:\n",
        "            ax.remove()  # Remove unused subplots\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_kernels(model.conv1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can clearly see from the kernels that, as we move deeper into the network, the kernels become more complex and start to capture more abstract features. The first layer kernels capture simple patterns like edges and gradients, while the deeper layers capture more complex patterns and textures. This progression is expected as the network learns to extract higher-level features from the input images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1600x800 with 32 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def visualize_feature_maps(model, layer_name, image):\n",
        "    activation = {}\n",
        "    def hook_fn(m, i, o): activation[layer_name] = o\n",
        "    hook = getattr(model, layer_name).register_forward_hook(hook_fn)\n",
        "    \n",
        "    # Forward pass through the model\n",
        "    _ = model(image)\n",
        "    \n",
        "    # Detach the hook\n",
        "    hook.remove()\n",
        "\n",
        "    feature_maps = activation[layer_name].squeeze(0)\n",
        "    num_feature_maps = feature_maps.size(0)\n",
        "    num_cols = 8  # Adjust as needed\n",
        "    num_rows = num_feature_maps // num_cols + (num_feature_maps % num_cols != 0)\n",
        "\n",
        "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(num_cols * 2, num_rows * 2))\n",
        "    for i, ax in enumerate(axs.flat):\n",
        "        if i < num_feature_maps:\n",
        "            ax.imshow(feature_maps[i].cpu().detach().numpy(), cmap=\"gray\")\n",
        "            ax.axis('off')\n",
        "        else:\n",
        "            ax.remove()  # Remove unused subplots\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_feature_maps(model, 'conv1', image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can observe that each feature map captures different aspects of the input image, highlighting different patterns and textures. This diversity in feature maps allows the network to learn a rich representation of the input images, enabling it to make accurate predictions. The visualization of feature maps provides insights into how the network processes the input images and extracts relevant information for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l69a3r-KS-Te"
      },
      "source": [
        "### **PART B: Transfer Learning**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX6re9CCycLQ"
      },
      "source": [
        "#### 1. Load a Pretrained model (the simpler the better for computational efficiency e.g.resnet16). You are gonna use it to train your model on Fashion Mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "uMdhPbHZyhJR"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),  # ResNet's expected input size\n",
        "    transforms.Grayscale(num_output_channels=3),  # Convert to 3-channel RGB\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "val_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5cFP61nyeYg"
      },
      "source": [
        "#### 2. Freeze the BackBone of the pretrained model (Convolutions etc) and modify the final fully connected layer/layers that perform classification (make sure the new output dimension matches the number of classes in Fashion Mnist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "W3SDIPmLyh5t"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_classes = 10\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHQmtgS0yYC_"
      },
      "source": [
        "#### 3. Train the model on Fashion Mnist for a few epoches and log your train/val loss progress as well as the final model accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "OskIs86tymEi"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1,   100] loss: 1.306\n",
            "[1,   200] loss: 0.737\n",
            "[1,   300] loss: 0.611\n",
            "[1,   400] loss: 0.571\n",
            "[1,   500] loss: 0.559\n",
            "[1,   600] loss: 0.530\n",
            "[1,   700] loss: 0.515\n",
            "[1,   800] loss: 0.480\n",
            "[1,   900] loss: 0.497\n",
            "[2,   100] loss: 0.471\n",
            "[2,   200] loss: 0.466\n",
            "[2,   300] loss: 0.454\n",
            "[2,   400] loss: 0.466\n",
            "[2,   500] loss: 0.458\n",
            "[2,   600] loss: 0.462\n",
            "[2,   700] loss: 0.449\n",
            "[2,   800] loss: 0.441\n",
            "[2,   900] loss: 0.446\n",
            "[3,   100] loss: 0.432\n",
            "[3,   200] loss: 0.432\n",
            "[3,   300] loss: 0.448\n",
            "[3,   400] loss: 0.414\n",
            "[3,   500] loss: 0.447\n",
            "[3,   600] loss: 0.416\n",
            "[3,   700] loss: 0.420\n",
            "[3,   800] loss: 0.436\n",
            "[3,   900] loss: 0.432\n",
            "[4,   100] loss: 0.414\n",
            "[4,   200] loss: 0.412\n",
            "[4,   300] loss: 0.414\n",
            "[4,   400] loss: 0.410\n",
            "[4,   500] loss: 0.406\n",
            "[4,   600] loss: 0.421\n",
            "[4,   700] loss: 0.408\n",
            "[4,   800] loss: 0.407\n",
            "[4,   900] loss: 0.430\n",
            "[5,   100] loss: 0.407\n",
            "[5,   200] loss: 0.393\n",
            "[5,   300] loss: 0.390\n",
            "[5,   400] loss: 0.399\n",
            "[5,   500] loss: 0.410\n",
            "[5,   600] loss: 0.396\n",
            "[5,   700] loss: 0.424\n",
            "[5,   800] loss: 0.413\n",
            "[5,   900] loss: 0.400\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:    # print every 100 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the test images: 85.62%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in val_loader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy of the model on the test images: {accuracy * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Achieving an accuracy of 85.62% on the test images with the adapted ResNet-18 model for the FashionMNIST dataset is a commendable result, especially considering the complexity and variability inherent in fashion item images. This outcome underscores the effectiveness of utilizing transfer learning techniques, where a model pre-trained on a large and diverse dataset is fine-tuned for a specific task. By retraining only the final layer of the ResNet-18 model to classify 10 different types of fashion items, while keeping the rest of the model's weights fixed, significant computational resources and time were saved. This approach not only leverages the pre-trained model's ability to extract general features from images but also tailors it to the specifics of the FashionMNIST dataset, resulting in high accuracy with relatively minimal effort. This success highlights the practicality and efficiency of transfer learning in real-world applications, particularly in domains where collecting a vast amount of labeled data is challenging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pm8mzHuKykll"
      },
      "source": [
        "#### **Optional:** If you are interested you can also unfreeze the final convolutions of the pretrained model to Fine Tune it. You can even visualize the Feature Maps of you model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yORqJmiOY2Qm"
      },
      "source": [
        "#### *Guidelines*: The goal of this assignment is that you play around a little bit with terms and notions introduced. You don' t have to train your models for ages. 5-10 epoches will suffice. We just want to see that you can make a model properly, train it and log some results."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
